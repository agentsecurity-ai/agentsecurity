"""
OpenAI Support Agent â€” Example companion code for AGENTSECURITY.md

Demonstrates AGENTSECURITY.md integration with the OpenAI Agents SDK.
The security policy applies regardless of which OpenAI model you use
(gpt-4o, gpt-5-mini, o3, etc.) and can be adapted for any provider.
"""

# --- AGENTSECURITY.md enforcement points ---
#
# 1. TOOL DECLARATION: Every tool below must be listed in AGENTSECURITY.md
# 2. SCOPE LIMITS: ticketing_api has denied_operations: [delete_ticket, close_ticket]
# 3. HITL GATE: ticket_status_change and customer_visible_response require approval
# 4. NETWORK: Only api.openai.com and tickets.example.internal are allowed

MAX_STEPS = 80
ALLOWED_OPERATIONS = ["read_ticket", "update_tags", "draft_reply"]
DENIED_OPERATIONS = ["delete_ticket", "close_ticket", "export_all"]


def read_ticket(ticket_id: str) -> dict:
    """Read a support ticket. Declared in AGENTSECURITY.md tools section."""
    # In production: call your ticketing API
    return {"id": ticket_id, "subject": "Example ticket", "status": "open"}


def update_tags(ticket_id: str, tags: list) -> dict:
    """Update ticket tags. Declared in AGENTSECURITY.md tools section."""
    return {"id": ticket_id, "tags": tags, "updated": True}


def draft_reply(ticket_id: str, content: str) -> dict:
    """Draft a reply. Requires human approval before sending (HITL gate)."""
    # AGENTSECURITY.md: human_in_the_loop.always_require: customer_visible_response_send
    print(f"[HITL REQUIRED] Draft reply for {ticket_id}: {content[:50]}...")
    return {"id": ticket_id, "draft": content, "status": "pending_approval"}


def close_ticket(ticket_id: str) -> dict:
    """BLOCKED: This operation is in denied_operations."""
    raise PermissionError(
        "close_ticket is denied by AGENTSECURITY.md "
        "tools.ticketing_api.scope.denied_operations"
    )


def main():
    """
    Skeleton showing AGENTSECURITY.md enforcement with OpenAI Agents SDK.

    To run with real OpenAI SDK:
      pip install openai
      export OPENAI_API_KEY=...

    The same AGENTSECURITY.md policy works if you swap to:
      - Anthropic: pip install anthropic
      - Google: pip install google-generativeai
      - Mistral: pip install mistralai
      - Any OpenAI-compatible API (Groq, Together, etc.)
    """

    # from openai import OpenAI
    # client = OpenAI()
    #
    # # Inject security context into system prompt
    # # Generated by: agentsec to-prompt .
    # system_prompt = """
    # <agent_security_policy>
    #   <name>openai-support-agent</name>
    #   <tier>standard</tier>
    #   <enforcement>warn</enforcement>
    # </agent_security_policy>
    #
    # You are a support triage agent. Follow the security policy above.
    # """

    print("OpenAI Support Agent (skeleton)")
    print(f"Max Steps: {MAX_STEPS}")
    print(f"Allowed Ops: {ALLOWED_OPERATIONS}")
    print(f"Denied Ops: {DENIED_OPERATIONS}")
    print("\nTo validate: agentsec validate .")
    print("To scan:     agentsec check .")


if __name__ == "__main__":
    main()
